import streamlit as st
from frontend.controller import offline_container
from somlier.application.use_cases.offline.create import CreateBatchRequest, CreateBatchRequestV2

use_case = offline_container.container.create()
use_case_v2 = offline_container.container.create_v2()


st.markdown("## Offline Serving (Airflow DAGs) ğŸ˜")
st.markdown("""---""")

offline_serving_type = st.radio("Serving Type", ("Use Docker Image", "Use SOCAR Data Provider"))

dag_schedule_interval = st.text_input("DAG Schedule Interval", placeholder="DAGì˜ ì‹¤í–‰ ì£¼ê¸°ë¥¼ cronjob í‘œí˜„ì‹ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”.")
dag_id = st.text_input("DAG ID", placeholder="DAG IDë¥¼ ì…ë ¥í•˜ì„¸ìš”. DAG IDëŠ” Uniqueí•´ì•¼í•©ë‹ˆë‹¤.")

if offline_serving_type == "Use Docker Image":
    docker_image = st.text_input(
        "Docker Image Reference", placeholder="ë„ì»¤ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", help="e.g., gcr.io/socar-data-dev/sift:latest"
    )
    docker_entrypoint = st.text_input(
        "Docker Container Entrypoint", placeholder="ë„ì»¤ ì»¨í…Œì´ë„ˆì˜ Entrypointë¥¼ ì…ë ¥í•˜ì„¸ìš”.", help="e.g., sh -c predict.sh"
    )

    use_dry_run = st.checkbox("Use Dry Run")
    check_airflow = st.checkbox("Check Airflow DAG Using REST API")

    submitted = st.button(
        "Serve Model ğŸ”–", disabled=not dag_id or not dag_schedule_interval or not docker_image or not docker_entrypoint
    )
    if submitted:
        req = CreateBatchRequest(
            docker_image=docker_image, schedule=dag_schedule_interval, entrypoint=docker_entrypoint, dag_id=dag_id
        )
        res = use_case.execute(req)
        st.success(f"DAG ìŠ¤í¬ë¦½íŠ¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.download_button("Download DAG Script File", data=res.dag, file_name=f"somlier_offline_dag_{dag_id}.py")


else:
    dag_start_date = st.date_input("DAG Start Date").strftime("%Y-%m-%d")
    mlflow_model_ref = st.text_input(
        "MLflow Model Reference",
        placeholder="MLflow Model Registryì— ì¡´ì¬í•˜ëŠ” ëª¨ë¸ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
        help="e.g., boston-house-pricing/2",
    )
    dataset_ref = st.text_input(
        "Feature Dataset Table Reference (BigQuery)",
        placeholder="ëª¨ë¸ì˜ ì…ë ¥ì´ ë  BigQuery í…Œì´ë¸” ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
        help="e.g., temp_serena.boston_house_pricing_feature_set",
    )
    dataset_load_column = st.text_input(
        "Column Name for Loading Dataset",
        placeholder="ì¸í¼ëŸ°ìŠ¤ ëŒ€ìƒì˜ ê¸°ì¤€ì´ ë˜ëŠ” ì»¬ëŸ¼ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.",
        help="e.g., date",
    )
    dataset_load_by_kst = (
        st.radio("Column Timezone for Loading Dataset", ("KST(Asia/Seoul')", "UTC")) == "KST(Asia/Seoul')"
    )
    destination_table_ref = st.text_input(
        "Destination Table Reference (BigQuery)",
        placeholder="ì¸í¼ëŸ°ìŠ¤ ê²°ê³¼ê°’ì´ ì ì¬ë  BigQuery í…Œì´ë¸” ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
        help="e.g., temp_serena.boston_house_pricing_result",
    )
    github_personal_access_token = st.text_input(
        "Github Personal Access Token",
        type="password",
        placeholder="Pull Request ìƒì„±ì„ ìœ„í•œ Personal Access Token ê°’",
    )
    submitted = st.button(
        "Serve Model ğŸ”–",
        disabled=not dag_id
        or not dag_schedule_interval
        or not dag_start_date
        or not mlflow_model_ref
        or not dataset_ref
        or not dataset_load_column
        or not destination_table_ref
        or not github_personal_access_token,
    )

    if submitted:
        req = CreateBatchRequestV2(
            model_ref=mlflow_model_ref,
            dag_id=dag_id,
            schedule_interval=dag_schedule_interval,
            start_date=dag_start_date,
            dataset_ref=dataset_ref,
            dataset_load_column=dataset_load_column,
            dataset_load_by_kst=dataset_load_by_kst,
            dataset_load_window=1,
            destination_table_ref=destination_table_ref,
            github_personal_access_token=github_personal_access_token,
        )
        res = use_case_v2.execute(req)
        st.success(f"DAG ìƒì„± ë° PR ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.success(res.msg)
